{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import AdamW\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Geração de labels aleatórios\n",
        "def get_random_label(description, animals):\n",
        "    words = description.split()\n",
        "    mentioned_animals = [animal for animal in animals if animal in words]\n",
        "    if not mentioned_animals:\n",
        "        return None\n",
        "    chosen_animal = random.choice(mentioned_animals)\n",
        "    label = label_encoder.transform([chosen_animal])[0]\n",
        "    return label\n",
        "\n",
        "\n",
        "# Dataset personalizado\n",
        "class AnimalDataset(Dataset):\n",
        "    def __init__(self, descriptions, labels, tokenizer, max_len=128):\n",
        "        self.descriptions = descriptions\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.descriptions)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        description = self.descriptions[index].strip()\n",
        "        label = self.labels[index]\n",
        "        inputs = self.tokenizer(\n",
        "            description,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "adTE_f7buWzF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqhvfpTMl8i9",
        "outputId": "3d7c25c2-1c9b-4592-aa47-056fd8e1e5f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 63/63 [00:10<00:00,  5.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 completed with loss 2.0102224349975586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:10<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 completed with loss 1.1343129873275757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:10<00:00,  5.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 completed with loss 1.1851214170455933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:10<00:00,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 completed with loss 1.1384773254394531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:10<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 completed with loss 1.3271236419677734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:10<00:00,  5.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 completed with loss 1.40555739402771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:10<00:00,  5.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 completed with loss 0.9634329080581665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:10<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 completed with loss 0.9415532350540161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:10<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 completed with loss 0.6611301898956299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:10<00:00,  5.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 completed with loss 1.4666528701782227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "with open('data/animal_descriptions.txt', 'r') as file:\n",
        "    descriptions = file.readlines()\n",
        "\n",
        "# Lista de animais\n",
        "animals = [\"dog\", \"horse\", \"elephant\", \"butterfly\", \"chicken\", \"cat\", \"cow\", \"sheep\", \"spider\", \"squirrel\"]\n",
        "\n",
        "# Inicializar o LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(animals)\n",
        "\n",
        "# Aplicar a função para gerar labels aleatórios\n",
        "random_labels = [get_random_label(desc, animals) for desc in descriptions]\n",
        "filtered_descriptions = [desc for desc, label in zip(descriptions, random_labels) if label is not None]\n",
        "filtered_labels = [label for label in random_labels if label is not None]\n",
        "\n",
        "\n",
        "# Configuração do modelo BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=len(animals)  # Número de classes\n",
        ")\n",
        "\n",
        "# Configuração do DataLoader e Otimizador\n",
        "dataset = AnimalDataset(filtered_descriptions, filtered_labels, tokenizer)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Definir a função de perda\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Definir o dispositivo (GPU ou CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "loss_arr = []\n",
        "\n",
        "# Loop de Treinamento\n",
        "model.train()\n",
        "for epoch in range(10):  # Número de épocas\n",
        "    for batch in tqdm(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = loss_fn(outputs.logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_arr.append(loss.item())\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} completed with loss {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_animal_probabilities(model, description, tokenizer, label_encoder):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(description, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probabilities = F.softmax(logits, dim=-1)  # Aplicar softmax para obter as probabilidades\n",
        "\n",
        "    # Converter as probabilidades para um array no CPU\n",
        "    probabilities = probabilities.cpu().numpy().flatten()\n",
        "\n",
        "    # Obter os nomes das classes usando o LabelEncoder\n",
        "    class_names = label_encoder.inverse_transform(range(len(probabilities)))\n",
        "\n",
        "    # Associar probabilidades com os nomes das classes corretamente\n",
        "    animal_probabilities = {class_name: f\"{prob*100:.2f}%\" for class_name, prob in zip(class_names, probabilities)}\n",
        "\n",
        "    # Imprimir as probabilidades para cada animal\n",
        "    print(f\"Description: {description}\")\n",
        "    print(\"Probabilities:\")\n",
        "    for animal, prob in animal_probabilities.items():\n",
        "        print(f\"{animal}: {prob}\")\n",
        "\n",
        "    return animal_probabilities"
      ],
      "metadata": {
        "id": "7THC9Hvzq2uF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de frase para teste\n",
        "test_description = \"A butterfly flying over a dog\"\n",
        "animal_probabilities = print_animal_probabilities(model, test_description, tokenizer, label_encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah20VyzXrT9V",
        "outputId": "371b4604-f781-48fb-c9b6-31e61713d593"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Description: A butterfly flying over a dog\n",
            "Probabilities:\n",
            "butterfly: 52.07%\n",
            "cat: 0.94%\n",
            "chicken: 1.56%\n",
            "cow: 0.72%\n",
            "dog: 35.96%\n",
            "elephant: 2.40%\n",
            "horse: 2.27%\n",
            "sheep: 1.22%\n",
            "spider: 1.27%\n",
            "squirrel: 1.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model/model.pt')"
      ],
      "metadata": {
        "id": "x81nckRGvKTA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oPFH-vplwHIJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}